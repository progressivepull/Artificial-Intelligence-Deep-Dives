# 3.2 Amazon SageMaker Clarify

Amazon SageMaker Clarify is a set of capabilities within Amazon SageMaker that helps data scientists and developers improve machine learning (ML) models by detecting potential bias and increasing model explainability. It provides tools to build responsible AI by analyzing data and models at various stages of the ML lifecycle—from data preparation to post-deployment monitoring.

---

## Key Capabilities

### Bias Detection and Mitigation

SageMaker Clarify helps uncover unintended bias in both datasets and trained models, which is essential for building fair and ethical AI systems.

- **Data Preparation**  
  Analyze datasets to identify imbalances (e.g., age, gender, race). Clarify provides detailed reports with bias metrics. This can be run directly from SageMaker Data Wrangler.

- **Model Training**  
  Evaluate trained models to detect bias in predictions across different groups. For example, check if negative outcomes are disproportionately assigned to a specific demographic.

- **Model Monitoring**  
  Bias can emerge over time as data shifts. Clarify integrates with SageMaker Model Monitor to detect bias drift and send alerts via Amazon CloudWatch.

### Model Explainability

Clarify provides insights into how models make predictions, helping build trust and meet compliance requirements.

- **Global Feature Importance**  
  Uses SHAP (SHapley Additive exPlanations) to show which features most influence overall predictions.

- **Local Feature Importance**  
  Explains individual predictions by breaking down feature contributions—useful for debugging and customer communication.

- **Support for Diverse Data**  
  Works with tabular, NLP, and computer vision models.

### Foundation Model (FM) Evaluation

Clarify supports evaluation of generative AI models and large language models (LLMs).

- **Automated and Human-in-the-Loop Evaluation**  
  Assess models on accuracy, robustness, and toxicity. Supports human-based evaluation for nuanced metrics.

---

## Integration with the ML Workflow

SageMaker Clarify integrates with other SageMaker services to support responsible AI across the ML lifecycle:

- **SageMaker Data Wrangler**  
  Visually identify and correct data bias during preparation.

- **SageMaker Pipelines**  
  Embed bias detection and explainability into automated workflows.

- **SageMaker Model Monitor**  
  Continuously monitor deployed models for bias drift and feature importance changes.

- **SageMaker Model Cards**  
  Automatically attach Clarify's reports to model cards for governance documentation.

---

## Example Use Case: Loan Application Approval

A financial institution uses ML to approve or deny loan applications.

1. **Detect Data Bias**  
   Clarify reveals underrepresentation of a neighborhood in training data. The team collects more representative samples.

2. **Evaluate Trained Model**  
   Clarify shows the model unfairly penalizes a demographic group. Retraining is performed.

3. **Explain Predictions**  
   A loan officer uses Clarify to understand why an applicant was denied—credit history was weighted heavily.

4. **Monitor for Bias Drift**  
   After deployment, Clarify detects a shift in feature importance due to housing market changes and alerts the team to retrain the model.

---

## Resources

- [AWS re:Invent 2020: Understand ML Model Predictions & Biases with Amazon SageMaker Clarify](https://www.youtube.com/watch?v=t2SJTYiTnYM)  
- [AWS re:Invent 2023 – Accelerate Foundation Model Evaluation with Amazon SageMaker Clarify (AIM367)](https://www.youtube.com/watch?v=9X2oDkOBYyA)


## [Context](./../context.md)
