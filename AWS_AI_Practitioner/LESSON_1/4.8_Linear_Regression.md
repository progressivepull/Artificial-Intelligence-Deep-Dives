# 📈 Linear Regression Overview

Linear regression is a statistical method for modeling the relationship between a dependent variable and one or more independent variables. Its core purpose is to find a **line of best fit** that represents the trend in the data, enabling predictions and insights into the strength of relationships.

---

## 🔍 Key Concepts

- **Dependent variable $$(y$$)**: The outcome you want to predict.
- **Independent variable(s) $$(x$$)**: The predictors used to make the forecast.

---

## 🧠 Types of Linear Regression

### 1. Simple Linear Regression
- **Definition**: Involves one independent variable to predict a single dependent variable.
- **Equation**:  
  

$$
  y = \beta_0 + \beta_1x + \varepsilon
  $$


- **Example**: Predicting a person's weight based on their height.

### 2. Multiple Linear Regression
- **Definition**: Uses two or more independent variables to predict the dependent variable.
- **Equation**:  
  

$$
  y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \dots + \beta_nx_n + \varepsilon
  $$


- **Example**: Predicting a house's price based on its size, location, and age.

### 3. Polynomial Regression
- **Definition**: Models a curved, non-linear relationship using polynomial terms, but remains linear in parameters.
- **Example Term**:  
  

$$
  x^2
  $$



---

## ⚙️ How Linear Regression Works

The goal is to minimize the total error between actual data points and predicted values using the **least squares method**:

1. **Plot the data**: Scatter plot with \(x$$ on the horizontal axis and \(y$$ on the vertical.
2. **Draw a line**: A straight line is fitted through the data.
3. **Measure the error**: Vertical distance (residual) between each point and the line.
4. **Square the errors**: Prevents cancellation and emphasizes larger errors.
5. **Minimize total error**: Adjusts the line to minimize the sum of squared errors.

---

## 📊 Interpreting the Results

- **Coefficients $$$$beta$$)**:  
  - Positive → both variables increase together  
  - Negative → one increases as the other decreases

- **\(R^2$$ (R-squared)**:  
  - Proportion of variance in \(y$$ explained by the model  
  - Ranges from 0 to 1

- **P-values**:  
  - Tests if a coefficient is significantly different from zero  
  - Typically, \(p < 0.05$$ indicates statistical significance

---

## ✅ Assumptions of Linear Regression

To ensure reliable results, the following assumptions must hold:

- Linear relationship between variables
- Independent residuals
- Constant variance of residuals (homoscedasticity)
- Normally distributed residuals
- No perfect multicollinearity among independent variables

---

## 🎥 Helpful Videos

- [Linear Regression in 3 Minutes](https://www.youtube.com/watch?v=3dhcmeOTZ_Q)
- [The Linear Regression Model](https://www.youtube.com/watch?v=m88h75F3Rl8)
