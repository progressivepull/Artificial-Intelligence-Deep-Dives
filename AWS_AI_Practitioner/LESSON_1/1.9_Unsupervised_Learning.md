# ğŸ§© 1.9 Unsupervised Learning

Unsupervised learning is a type of machine learning that uses algorithms to analyze and cluster **unlabeled datasets**. Unlike supervised learning, it requires no human intervention or pre-existing labels to discover hidden patterns, structures, and relationships within data.

---

## ğŸ” How Unsupervised Learning Works
With unsupervised learning, the model is given raw, unlabeled data and has to infer its own rules and structure the information based on similarities, differences, and patterns.  

**General steps:**
1. **Data collection and cleaning** â€“ Collect an unlabeled dataset, merge datasets if needed, remove duplicates, and correct errors.  
2. **Algorithm selection** â€“ Choose an algorithm depending on the task (e.g., clustering, dimensionality reduction).  
3. **Pattern discovery** â€“ The algorithm processes the data to uncover relationships and patterns.  
4. **Interpretation** â€“ A human reviews and validates the discovered patterns.  
5. **Application** â€“ Insights are applied to tasks like segmentation or anomaly detection.  

---

## ğŸ”‘ Key Types of Unsupervised Learning

### 1. Clustering
Grouping similar data points together based on shared characteristics.  
- **K-means clustering** â€“ Divides data into a user-defined number of clusters using the mean distance to each clusterâ€™s center (centroid).  
- **Hierarchical clustering** â€“ Organizes data into a tree-like structure of nested clusters.  
- **Probabilistic clustering** â€“ Assigns data points to clusters based on probabilities.  

**Applications:** Customer segmentation, grouping news articles, medical image clustering.

---

### 2. Association Rule Learning
Discovers **if-then patterns** and relationships between variables in large datasets.  
- **Algorithms:** Apriori, FP-Growth.  
- **Applications:** Market basket analysis (â€œcustomers who buy X also buy Yâ€), recommendation engines, medical symptom relationship analysis.  

---

### 3. Dimensionality Reduction
Reduces the number of features while keeping essential information.  
- **Principal Component Analysis (PCA):** Linear transformation identifying key components explaining most variance.  
- **Autoencoders:** Neural networks that learn compressed representations of input data.  

**Applications:** Image recognition, data compression, improving model efficiency and speed.  

---

## âš–ï¸ Unsupervised vs. Supervised Learning

| Aspect      | Unsupervised Learning | Supervised Learning |
|-------------|-----------------------|---------------------|
| **Data**    | Unlabeled, no predefined categories | Labeled, with input-output pairs |
| **Goal**    | Discover hidden patterns, structures, and relationships | Predict outcomes for new data |
| **Process** | Algorithm works independently to find patterns | Algorithm learns from labeled examples and adjusts predictions |
| **Use Case**| Exploratory data analysis, segmentation, anomaly detection | Classification (e.g., spam detection), regression (e.g., house price prediction) |

---

# ğŸ¬ Key Insights from [Unsupervised Learning: Crash Course AI #6](https://www.youtube.com/watch?v=JnnaDNNb380)

This episode explains **unsupervised learning** by comparing it to how we naturally make sense of the world without labels or guidance.

---

## ğŸ§  Core Ideas

- **No teacher / no labels**  
  Unlike supervised learning (where data comes with labels like *â€œcatâ€* or *â€œspamâ€*), unsupervised learning relies solely on the **data itself** to reveal hidden patterns and structures.  

- **Modeling the world by guessing**  
  Algorithms form hypotheses about possible groupings (clusters), then refine them iteratively based on observations.  

---

## ğŸŒ¸ Example: Iris Flowers

1. Start with many iris flowers but **no species labels**.  
2. Choose measurable features (e.g., *petal length*, *petal width*).  
3. Guess the number of clusters (**K**).  
4. Randomly place cluster **centroids** and assign points to clusters.  
5. Update centroids (means), reassign points, and repeat until convergence.  
6. The resulting clusters may align with speciesâ€”even though the model never â€œknewâ€ species labels.  

---

## âš–ï¸ Assumptions & Limits

- Algorithms assume clusters exist and that **â€œsimilarâ€ points belong together**.  
- If real-world data doesnâ€™t fit these assumptions, clustering can mislead.  

---

## ğŸ”„ Iterative Refinement

Unsupervised methods (like **K-means**) alternate between:  

- **Prediction** â†’ assign points to clusters  
- **Correction** â†’ update cluster centers  

This continues until the assignments stabilize.  

---

## ğŸ“Š Usefulness & Limitations

- **Strengths**:  
  - Leverages large amounts of unlabeled data (images, text, etc.).  
  - Helps discover structure without manual labeling.  

- **Limitations**:  
  - No ground truth means human interpretation is necessary.  
  - Patterns found may not always reflect meaningful categories.  

---


# ğŸ¥ Highlights from [Unsupervised Learning - AI Basics](https://www.youtube.com/watch?v=5yeJ03crTrI)

This introductory video explains what unsupervised learning is, why it matters, and the types of tasks it addresses.

---

## ğŸ”‘ Key Points

- **Pattern discovery without labels**  
  Unsupervised learning enables computers to identify patterns in data without explicit training labels.  

- **Exploratory by nature**  
  With no labels provided, the algorithmâ€™s goal is to uncover hidden structures such as:  
  - Clusters  
  - Associations  
  - Low-dimensional embeddings  

- **Real-world motivations**  
  Although touched on briefly, examples include:  
  - Grouping similar items  
  - Revealing hidden or latent relationships in datasets  

---


## [Context](./../context.md)
