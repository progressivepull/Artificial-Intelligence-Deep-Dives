# 3.1 Amazon SageMaker Data Wrangler

Amazon SageMaker Data Wrangler is a fully managed, visual interface that simplifies and accelerates the process of data preparation and feature engineering for machine learning (ML). It helps data scientists and engineers reduce the time spent on data preparation—often cited as 80% of an ML project—from weeks to minutes.

Data Wrangler is a core component of SageMaker Studio and integrates with other SageMaker services to create end-to-end ML workflows.

---

## Key Capabilities

### Visual Data Preparation

Data Wrangler provides a code-optional, visual interface where you can:

- **Connect to Data Sources**  
  Access data from Amazon S3, Amazon Athena, Amazon Redshift, Snowflake, and more with a single click.

- **Visually Transform Data**  
  Use over 300 built-in transformations for tabular, image, and text data, including:
  - **Data Cleaning**: Handle missing values, remove duplicates, encode categorical variables.
  - **Feature Engineering**: Create new features, rescale columns, apply PCA.
  - **Augmentation**: Enhance image and text data for better training.

- **Create Custom Transformations**  
  Use PySpark, SQL, or pandas for advanced tasks directly within the interface.

### Data Insights and Analysis

- **Data Quality and Insights Report**  
  Automatically summarizes statistics, missing values, outliers, class imbalance, and target leakage.

- **Quick Model Analysis**  
  Estimates predictive power of your data before full model training.

- **Bias Report**  
  Integrates with SageMaker Clarify to detect potential biases in features.

- **Visualizations**  
  Generate histograms, scatter plots, bar charts, and more with a few clicks.

### Streamlined MLOps Integration

- **Export Data Flow**  
  Save your transformations as a `.flow` file and export to Jupyter, Python, or SageMaker Pipelines.

- **SageMaker Pipelines**  
  Automate end-to-end workflows including training and deployment.

- **SageMaker Feature Store**  
  Publish features for reuse across teams and models.

- **Processing Jobs**  
  Scale data prep to petabyte-level workloads using SageMaker Processing.

---

## Example Use Case: Churn Prediction

A telecommunications company wants to predict customer churn.

1. **Import Data**  
   Connect Data Wrangler to an S3 bucket with customer usage logs, plan details, and billing history.

2. **Explore and Analyze**  
   Generate a Data Quality and Insights Report. Identify missing values in `customer_service_calls` and recognize `plan_type` as categorical.

3. **Transform and Engineer Features**  
   - Impute missing values in `customer_service_calls` with the median.
   - Apply one-hot encoding to `plan_type`.
   - Use SQL to create a `call_frequency` feature: `total_calls / subscription_length`.

4. **Export the Workflow**  
   Export the data flow to a SageMaker Pipeline for automated retraining on new data.

5. **Store Features**  
   Ingest processed features into SageMaker Feature Store for reuse in other ML projects.

---

## Resources

- [Amazon SageMaker Data Wrangler and Snowflake Demo](https://www.youtube.com/watch?v=9UxsJdLql-8)  
- [First Look – AWS SageMaker Data Wrangler](https://www.youtube.com/watch?v=JDCTNcE17iw)


## [Context](./../context.md)

